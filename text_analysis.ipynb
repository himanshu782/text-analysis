{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>CONAME</th>\n",
       "      <th>FYRMO</th>\n",
       "      <th>FDATE</th>\n",
       "      <th>FORM</th>\n",
       "      <th>SECFNAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199803</td>\n",
       "      <td>1998-03-06</td>\n",
       "      <td>10-K405</td>\n",
       "      <td>edgar/data/3662/0000950170-98-000413.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199805</td>\n",
       "      <td>1998-05-15</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/3662/0000950170-98-001001.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199808</td>\n",
       "      <td>1998-08-13</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-000783.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-12</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002145.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-16</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-001203.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CIK            CONAME   FYRMO      FDATE     FORM  \\\n",
       "0  3662  SUNBEAM CORP/FL/  199803 1998-03-06  10-K405   \n",
       "1  3662  SUNBEAM CORP/FL/  199805 1998-05-15     10-Q   \n",
       "2  3662  SUNBEAM CORP/FL/  199808 1998-08-13  NT 10-Q   \n",
       "3  3662  SUNBEAM CORP/FL/  199811 1998-11-12   10-K/A   \n",
       "4  3662  SUNBEAM CORP/FL/  199811 1998-11-16  NT 10-Q   \n",
       "\n",
       "                                   SECFNAME  \n",
       "0  edgar/data/3662/0000950170-98-000413.txt  \n",
       "1  edgar/data/3662/0000950170-98-001001.txt  \n",
       "2  edgar/data/3662/0000950172-98-000783.txt  \n",
       "3  edgar/data/3662/0000950170-98-002145.txt  \n",
       "4  edgar/data/3662/0000950172-98-001203.txt  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"cik_list.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"https://www.sec.gov/\"\n",
    "links = [y + x for x in df[\"SECFNAME\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toatal 152 reports saved\n"
     ]
    }
   ],
   "source": [
    "reports = []\n",
    "for url in links:\n",
    "    r = requests.get(url)\n",
    "    data = r.text\n",
    "    soup = BeautifulSoup(data, \"html.parser\")\n",
    "    reports.append(soup.get_text())\n",
    "\n",
    "print(f\"Toatal {len(reports)} reports saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of stop Words are 121\n"
     ]
    }
   ],
   "source": [
    "with open(\"Stopwords_Generic.txt\",\"r\")as f:\n",
    "    stop_words = f.read()\n",
    "\n",
    "stop_words = stop_words.split(\"\\n\")\n",
    "print(f\"Total number of stop Words are {len(stop_words)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Seq_num</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Word Proportion</th>\n",
       "      <th>Average Proportion</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Doc Count</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Litigious</th>\n",
       "      <th>Strong_Modal</th>\n",
       "      <th>Weak_Modal</th>\n",
       "      <th>Constraining</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AARDVARK</td>\n",
       "      <td>1</td>\n",
       "      <td>354</td>\n",
       "      <td>1.550080e-08</td>\n",
       "      <td>1.422600e-08</td>\n",
       "      <td>3.815486e-06</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AARDVARKS</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.313627e-10</td>\n",
       "      <td>8.653817e-12</td>\n",
       "      <td>9.241714e-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABACI</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3.940882e-10</td>\n",
       "      <td>1.169679e-10</td>\n",
       "      <td>5.290465e-08</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABACK</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1.269840e-09</td>\n",
       "      <td>6.654735e-10</td>\n",
       "      <td>1.595100e-07</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABACUS</td>\n",
       "      <td>5</td>\n",
       "      <td>8570</td>\n",
       "      <td>3.752595e-07</td>\n",
       "      <td>3.809464e-07</td>\n",
       "      <td>3.529356e-05</td>\n",
       "      <td>1108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word  Seq_num  Word Count  Word Proportion  Average Proportion  \\\n",
       "0   AARDVARK        1         354     1.550080e-08        1.422600e-08   \n",
       "1  AARDVARKS        2           3     1.313627e-10        8.653817e-12   \n",
       "2      ABACI        3           9     3.940882e-10        1.169679e-10   \n",
       "3      ABACK        4          29     1.269840e-09        6.654735e-10   \n",
       "4     ABACUS        5        8570     3.752595e-07        3.809464e-07   \n",
       "\n",
       "        Std Dev  Doc Count  Negative  Positive  Uncertainty  Litigious  \\\n",
       "0  3.815486e-06         99         0         0            0          0   \n",
       "1  9.241714e-09          1         0         0            0          0   \n",
       "2  5.290465e-08          7         0         0            0          0   \n",
       "3  1.595100e-07         28         0         0            0          0   \n",
       "4  3.529356e-05       1108         0         0            0          0   \n",
       "\n",
       "   Strong_Modal  Weak_Modal  Constraining  Syllables     Source  \n",
       "0             0           0             0          2  12of12inf  \n",
       "1             0           0             0          2  12of12inf  \n",
       "2             0           0             0          3  12of12inf  \n",
       "3             0           0             0          2  12of12inf  \n",
       "4             0           0             0          3  12of12inf  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_dic = pd.read_csv(\"Loughran_McDonald.csv\")\n",
    "master_dic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positive words in dictionary are 354\n",
      "Total negetive words in dictionary are 2355\n"
     ]
    }
   ],
   "source": [
    "positive_dictionary = [x for x in master_dic[master_dic[\"Positive\"] != 0][\"Word\"]]\n",
    "negetive_dictionary = [x for x in master_dic[master_dic[\"Negative\"] != 0][\"Word\"]]\n",
    "\n",
    "print(f\"Total positive words in dictionary are {len(positive_dictionary)}\")\n",
    "print(f\"Total negetive words in dictionary are {len(negetive_dictionary)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainity = pd.read_excel(\"uncertainty_dictionary.xlsx\")\n",
    "uncertainity_words = list(uncertainity[\"Word\"])\n",
    "\n",
    "constraining = pd.read_excel(\"constraining_dictionary.xlsx\")\n",
    "constraining_words = list(constraining[\"Word\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = re.sub(r'[^A-Za-z]', \" \",text.upper())\n",
    "    tokenized_words = word_tokenize(text)\n",
    "    return tokenized_words\n",
    "\n",
    "def remove_stopwords(words, stop_words):\n",
    "    return [x for x in words if x not in stop_words]\n",
    "\n",
    "def countfnc(store, words):\n",
    "    score = 0\n",
    "    for x in words:\n",
    "        if(x in store):\n",
    "            score = score+1\n",
    "    return score\n",
    "\n",
    "def sentiment(score):\n",
    "    if(score < -0.5):\n",
    "        return \"Most Negative\"\n",
    "    elif(score >= -0.5 and score < 0):\n",
    "        return \"Negative\"\n",
    "    elif(score == 0):\n",
    "        return \"Neutral\"\n",
    "    elif(score > 0 and score < 0.5):\n",
    "        return \"Positive\"\n",
    "    else:\n",
    "        return \"Very Positive\"\n",
    "\n",
    "def polarity(positive_score, negetive_score):\n",
    "    return (positive_score - negetive_score)/((positive_score + negetive_score)+ 0.000001)\n",
    "\n",
    "\n",
    "def subjectivity(positive_score, negative_score,num_words):\n",
    "    return (positive_score+negative_score)/(num_words+ 0.000001)\n",
    "\n",
    "def syllable_morethan2(word):\n",
    "    if(len(word)> 2 and (word[-2:]==\"es\" or word[-2:] == \"ed\")):\n",
    "        return False\n",
    "\n",
    "    count =0\n",
    "    vowels = [\"a\",'e','i','o','u']\n",
    "    for i in word:\n",
    "        if(i.lower() in vowels):\n",
    "            count = count +1\n",
    "\n",
    "    if(count > 2):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def fog_index_cal(average_sentence_length, percentage_complexwords):\n",
    "    return 0.4*(average_sentence_length + percentage_complexwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = [\"Management's Discussion and Analysis\",\n",
    "            \"Quantitative and Qualitative Disclosures about Market Risk\\n\",\n",
    "            \"Risk Factors\\n\"]\n",
    "caps = [x.upper() for x in sections]\n",
    "caps.extend(sections)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"mda\",'qqdmr','rf']\n",
    "var = [\"positive_score\",\n",
    "       'negetive_score',\n",
    "       'polarity_score',\n",
    "       'average_sentence_legth',\n",
    "       'percentage_of_complex_words',\n",
    "       'fog_index',\n",
    "       'complex_word_count',\n",
    "       'word_count',\n",
    "       'uncertainity_score',\n",
    "       'constraining_score',\n",
    "       'positive_word_proportion',\n",
    "       'negetive_word_proportion',\n",
    "       \"uncertainity_word_proportion\",\n",
    "       'constraining_word_proportion',\n",
    "       'constraining_words_whole_report']\n",
    "\n",
    "for c in col:\n",
    "    for v in var[:1]:\n",
    "        df[c+\"_\"+v] = 0.0\n",
    "\n",
    "df[var[-1]] = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>CONAME</th>\n",
       "      <th>FYRMO</th>\n",
       "      <th>FDATE</th>\n",
       "      <th>FORM</th>\n",
       "      <th>SECFNAME</th>\n",
       "      <th>mda_positive_score</th>\n",
       "      <th>qqdmr_positive_score</th>\n",
       "      <th>rf_positive_score</th>\n",
       "      <th>constraining_words_whole_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199803</td>\n",
       "      <td>1998-03-06</td>\n",
       "      <td>10-K405</td>\n",
       "      <td>edgar/data/3662/0000950170-98-000413.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199805</td>\n",
       "      <td>1998-05-15</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/3662/0000950170-98-001001.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199808</td>\n",
       "      <td>1998-08-13</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-000783.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-12</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002145.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-16</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-001203.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CIK            CONAME   FYRMO      FDATE     FORM  \\\n",
       "0  3662  SUNBEAM CORP/FL/  199803 1998-03-06  10-K405   \n",
       "1  3662  SUNBEAM CORP/FL/  199805 1998-05-15     10-Q   \n",
       "2  3662  SUNBEAM CORP/FL/  199808 1998-08-13  NT 10-Q   \n",
       "3  3662  SUNBEAM CORP/FL/  199811 1998-11-12   10-K/A   \n",
       "4  3662  SUNBEAM CORP/FL/  199811 1998-11-16  NT 10-Q   \n",
       "\n",
       "                                   SECFNAME  mda_positive_score  \\\n",
       "0  edgar/data/3662/0000950170-98-000413.txt                 0.0   \n",
       "1  edgar/data/3662/0000950170-98-001001.txt                 0.0   \n",
       "2  edgar/data/3662/0000950172-98-000783.txt                 0.0   \n",
       "3  edgar/data/3662/0000950170-98-002145.txt                 0.0   \n",
       "4  edgar/data/3662/0000950172-98-001203.txt                 0.0   \n",
       "\n",
       "   qqdmr_positive_score  rf_positive_score  constraining_words_whole_report  \n",
       "0                   0.0                0.0                              0.0  \n",
       "1                   0.0                0.0                              0.0  \n",
       "2                   0.0                0.0                              0.0  \n",
       "3                   0.0                0.0                              0.0  \n",
       "4                   0.0                0.0                              0.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_map = {i:j for i, j in zip(sections, col)}\n",
    "s_map = {i.upper():j for i,j in zip(sections, col)}\n",
    "\n",
    "section_map.update(s_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(reports)):\n",
    "    text = re.sub(\"Item\",'ITEM',reports[i])\n",
    "    for j in caps:\n",
    "        x = re.search(\"ITEM\\s+[\\d]\\(*A-Za-z]*.*\\s+\\-*\\s*\"+j, text)\n",
    "\n",
    "        if x:\n",
    "            start,end = x.span()\n",
    "            content = (text[start:]).split(\"ITEM\")[1]\n",
    "            if (\"...\"not in content) and (\"...\"not in content) and len(content) > 200:\n",
    "                tokenized_words = tokenize(content)\n",
    "                words = remove_stopwords(tokenized_words, stop_words)\n",
    "                num_words = len(words)\n",
    "                positive_score = countfnc(positive_dictionary, words)\n",
    "                negetive_score = countfnc(negetive_dictionary, words)\n",
    "\n",
    "                polarity_score = polarity(positive_score, negetive_score)\n",
    "                \n",
    "                subjectivity_score  = subjectivity(positive_score, negetive_score, num_words)\n",
    "\n",
    "                sentences = sent_tokenize(content)\n",
    "                num_sentences = len(sentences)\n",
    "                average_sentence_length = num_words/num_sentences\n",
    "\n",
    "                num_complexword = 0\n",
    "                uncertainity_score= 0\n",
    "                constraining_score = 0\n",
    "\n",
    "                for word in words:\n",
    "                    if(syllable_morethan2(word)):\n",
    "                        num_complexword = num_complexword+1\n",
    "\n",
    "                    if(word in uncertainity_words):\n",
    "                        uncertainity_score = uncertainity_score+1\n",
    "\n",
    "                    if(word in constraining_words):\n",
    "                        constraining_score = constraining_score+1\n",
    "\n",
    "                    percentage_complexwords = num_complexword/num_words\n",
    "\n",
    "                    fog_index = fog_index_cal(average_sentence_length, percentage_complexwords)\n",
    "\n",
    "                    positive_word_proportion = positive_score/num_words\n",
    "                    negative_word_proportion = negetive_score/num_words\n",
    "                    uncertainity_word_proportion = uncertainity_score/num_words\n",
    "                    constraining_word_proportion = constraining_score/num_words\n",
    "\n",
    "\n",
    "\n",
    "                    df.at[i,section_map[j]+'_positive_score'] = positive_score\n",
    "                    df.at[i,section_map[j]+'_negative_score'] = negative_score\n",
    "                    df.at[i,section_map[j]+'_polarity_score'] = polarity_score\n",
    "                    df.at[i,section_map[j]+'_average_sentence_length'] = average_sentence_length\n",
    "                    df.at[i,section_map[j]+'_percentage_of_complex_words'] = percentage_complexwords\n",
    "                    df.at[i,section_map[j]+'_fog_index'] = fog_index\n",
    "                    df.at[i,section_map[j]+'_complex_word_count'] = num_complexword\n",
    "                    df.at[i,section_map[j]+'_word_count'] = num_words\n",
    "                    df.at[i,section_map[j]+'_uncertainity_score'] = uncertainity_score\n",
    "                    df.at[i,section_map[j]+'_constraining_score'] = constraining_score\n",
    "                    df.at[i,section_map[j]+'_positive_word_proportion'] = positive_word_proportion\n",
    "                    df.at[i,section_map[j]+'_negative_word_proportion'] = negative_word_proportion\n",
    "                    df.at[i,section_map[j]+'_uncertainity_word_proportion'] = uncertainity_word_proportion\n",
    "                    df.at[i,section_map[j]+'_constraining_word_proportion'] = constraining_word_proportion\n",
    "\n",
    "\n",
    "        constraining_words_whole_reports = 0\n",
    "        tokenized_report_words = tokenize(reports[i])\n",
    "        report_words = remove_stopwords(tokenized_report_words, stop_words)\n",
    "        for word in report_words:\n",
    "            if word in constraining_words:\n",
    "                constraining_words_whole_reports = 1+ constraining_words_whole_reports\n",
    "        df.at[i, \"constraining_words_whole_report\"]= constraining_words_whole_reports\n",
    "\n",
    "                \n",
    "                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>CONAME</th>\n",
       "      <th>FYRMO</th>\n",
       "      <th>FDATE</th>\n",
       "      <th>FORM</th>\n",
       "      <th>SECFNAME</th>\n",
       "      <th>mda_positive_score</th>\n",
       "      <th>qqdmr_positive_score</th>\n",
       "      <th>rf_positive_score</th>\n",
       "      <th>constraining_words_whole_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199803</td>\n",
       "      <td>1998-03-06</td>\n",
       "      <td>10-K405</td>\n",
       "      <td>edgar/data/3662/0000950170-98-000413.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199805</td>\n",
       "      <td>1998-05-15</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/3662/0000950170-98-001001.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199808</td>\n",
       "      <td>1998-08-13</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-000783.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-12</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002145.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-16</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-001203.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CIK            CONAME   FYRMO      FDATE     FORM  \\\n",
       "0  3662  SUNBEAM CORP/FL/  199803 1998-03-06  10-K405   \n",
       "1  3662  SUNBEAM CORP/FL/  199805 1998-05-15     10-Q   \n",
       "2  3662  SUNBEAM CORP/FL/  199808 1998-08-13  NT 10-Q   \n",
       "3  3662  SUNBEAM CORP/FL/  199811 1998-11-12   10-K/A   \n",
       "4  3662  SUNBEAM CORP/FL/  199811 1998-11-16  NT 10-Q   \n",
       "\n",
       "                                   SECFNAME  mda_positive_score  \\\n",
       "0  edgar/data/3662/0000950170-98-000413.txt                 0.0   \n",
       "1  edgar/data/3662/0000950170-98-001001.txt                 0.0   \n",
       "2  edgar/data/3662/0000950172-98-000783.txt                 0.0   \n",
       "3  edgar/data/3662/0000950170-98-002145.txt                 0.0   \n",
       "4  edgar/data/3662/0000950172-98-001203.txt                 0.0   \n",
       "\n",
       "   qqdmr_positive_score  rf_positive_score  constraining_words_whole_report  \n",
       "0                   0.0                0.0                              0.0  \n",
       "1                   0.0                0.0                              0.0  \n",
       "2                   0.0                0.0                              0.0  \n",
       "3                   0.0                0.0                              0.0  \n",
       "4                   0.0                0.0                              0.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"output.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c3d4d9970fc5c09c50d9318a9c7fbf4d0159e4b28833276f5678ee22bded273"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
